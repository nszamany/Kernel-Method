{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully imported joblib.Parallel, it will be used to try to run training/projecting of multi-class SVC in parallel ...\n",
      "Succesfully imported numba.jit, it will be used to try to speed-up function calls ...\n",
      "Successfully imported joblib, it will be used to try to run training/predictions of multi-class KFD in parallel ...\n",
      "Successfully imported numba.jit, it will be used to try to speed-up function calls ...\n"
     ]
    }
   ],
   "source": [
    "import cvxopt\n",
    "import sys\n",
    "from sift import SIFT, Helper\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from svm import mySVC\n",
    "from KFD import myKFD\n",
    "from transform import myTransform\n",
    "from kernels import rbf, linear, poly, sigmoid, laplacian, ch2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load datasets\"\"\"\n",
    "\n",
    "# Training set\n",
    "X_df = pd.read_csv('./data/Xtr.csv', header=None)\n",
    "y_df = pd.read_csv('./data/Ytr.csv')\n",
    "X_df = X_df.loc[:,:3071]\n",
    "\n",
    "# Test set\n",
    "X_test = pd.read_csv('./data/Xte.csv', header=None)\n",
    "X_test = X_test.loc[:,:3071]\n",
    "\n",
    "X = X_df.values\n",
    "y = y_df.Prediction\n",
    "\n",
    "X_test = X_test.values\n",
    "\n",
    "\"\"\"Train and test image processing into 32x32x3 shape\"\"\"\n",
    "red, green, blue = np.hsplit(X, 3)\n",
    "data = np.array([np.dstack((red[i], blue[i], green[i])).reshape(32, 32, 3) for i in range(len(X))])\n",
    "\n",
    "red, green, blue = np.hsplit(X_test, 3)\n",
    "data_test = np.array([np.dstack((red[i], blue[i], green[i])).reshape(32, 32, 3) for i in range(len(X_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data augmentation with Gaussian blur or random horizontal flip.\"\"\"\n",
    "\n",
    "start = time()\n",
    "finish = len(data)\n",
    "augmented_train = []\n",
    "ImageTransformation = myTransform()  # Corrected instantiation\n",
    "\n",
    "for row in range(0, finish):\n",
    "    augmented_train.append(data[row])\n",
    "    augmented_train.append(ImageTransformation.flip_image_horizontal(data[row]))\n",
    "augmented_train = np.array(augmented_train)\n",
    "\n",
    "start = time()\n",
    "augmented_labels = []\n",
    "\n",
    "for row in range(len(data)):\n",
    "    lab = y[row]\n",
    "    augmented_labels.append(lab)\n",
    "    augmented_labels.append(lab)\n",
    "\n",
    "augmented_labels = np.array(augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT - 100.00% ----- Temps restant estimÃ©: 0 min 0 sec ------"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"We set SIFT parameters, the choice of them has been done based on existing information and empirically.\"\"\"\n",
    "\n",
    "params = { 'gs': 6,\n",
    "           'chi2_gamma': .6,\n",
    "           'C': 10.,\n",
    "           'ps': 31,\n",
    "           'sift_thres': .3,\n",
    "           'gaussian_thres': .7,\n",
    "           'gaussian_sigma': .4,\n",
    "           'num_angles': 12,\n",
    "           'num_bins': 5,\n",
    "           'alpha': 9.0 }\n",
    "\n",
    "sift = SIFT(gs=params['gs'], \n",
    "                 ps=params['ps'], \n",
    "                 sift_thres=params['sift_thres'], \n",
    "                 gaussian_sigma=params['gaussian_sigma'], \n",
    "                 gaussian_thres=params['gaussian_thres'],\n",
    "                 num_angles=params['num_angles'],\n",
    "                 num_bins=params['num_bins'],\n",
    "                 alpha=params['alpha'])\n",
    "\n",
    "\"\"\"With data augmentation we end up with 10000 vectors of dimension $n$, the number of SIFT features, for training.\"\"\"\n",
    "\n",
    "target = augmented_labels\n",
    "train = sift.get_X(augmented_train)\n",
    "test = sift.get_X(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  A new mySVC object has been created:\n",
      "    > mySVC(kernel=ch2, C=7.5, n_classes_=None, max_n_classes=10, degree=3, gamma=auto, coef0=1.0, threshold=0.001, verbose=1, n_jobs=1, cache_size=200)\n",
      "Training SVM on all training data ...\n",
      "  Training mySVC... on X of shape (10000, 300).\n",
      "  Using y of shape (10000,) with 10 different classes\n",
      "  BinarySVC parameters:\n",
      " {'kernel': 'ch2', 'C': 7.5, 'degree': 3, 'gamma': 'auto', 'coef0': 1.0, 'verbose': 1, 'cache_size': 200}\n",
      "  A new BinarySVC object has been created:\n",
      "    > BinarySVC(kernel=ch2, C=7.5, degree=3, gamma=auto, coef0=1.0, threshold=0.001, verbose=1, cache_size=200)\n",
      "  A new BinarySVC object has been created:\n",
      "    > BinarySVC(kernel=ch2, C=7.5, degree=3, gamma=auto, coef0=1.0, threshold=0.001, verbose=1, cache_size=200)\n",
      "  A new BinarySVC object has been created:\n",
      "    > BinarySVC(kernel=ch2, C=7.5, degree=3, gamma=auto, coef0=1.0, threshold=0.001, verbose=1, cache_size=200)\n",
      "  A new BinarySVC object has been created:\n",
      "    > BinarySVC(kernel=ch2, C=7.5, degree=3, gamma=auto, coef0=1.0, threshold=0.001, verbose=1, cache_size=200)\n",
      "  A new BinarySVC object has been created:\n",
      "    > BinarySVC(kernel=ch2, C=7.5, degree=3, gamma=auto, coef0=1.0, threshold=0.001, verbose=1, cache_size=200)\n",
      "  A new BinarySVC object has been created:\n",
      "    > BinarySVC(kernel=ch2, C=7.5, degree=3, gamma=auto, coef0=1.0, threshold=0.001, verbose=1, cache_size=200)\n",
      "  A new BinarySVC object has been created:\n",
      "    > BinarySVC(kernel=ch2, C=7.5, degree=3, gamma=auto, coef0=1.0, threshold=0.001, verbose=1, cache_size=200)\n",
      "  A new BinarySVC object has been created:\n",
      "    > BinarySVC(kernel=ch2, C=7.5, degree=3, gamma=auto, coef0=1.0, threshold=0.001, verbose=1, cache_size=200)\n",
      "  A new BinarySVC object has been created:\n",
      "    > BinarySVC(kernel=ch2, C=7.5, degree=3, gamma=auto, coef0=1.0, threshold=0.001, verbose=1, cache_size=200)\n",
      "  A new BinarySVC object has been created:\n",
      "    > BinarySVC(kernel=ch2, C=7.5, degree=3, gamma=auto, coef0=1.0, threshold=0.001, verbose=1, cache_size=200)\n",
      "  Computing the Gram matrix only once to speed up training time for each BinarySVC.\n",
      "  Computing Gram matrix for a BinarySVC for data X of shape (10000, 300) ...\n",
      "  Not using any parallelism for trainOneBinarySVC(k) for k = 0 .. 9 ...\n",
      "  - For the class k = 0:\n",
      "    There is 1000 examples in this class (and 9000 outside).\n",
      "  Training BinarySVC... on X of shape (10000, 300) ...\n",
      "  Using the given Gram matrix K.\n",
      "  Using the QP solver from cvxopt (cvxopt.qp) ...\n",
      "  More information on http://cvxopt.org/userguide/coneprog.html#quadratic-programming if needed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.2877e+03 -2.0743e+05  4e+05  3e-01  9e-15\n",
      " 1:  4.7316e+03 -5.5059e+04  8e+04  5e-02  3e-15\n",
      " 2:  1.2836e+03 -1.3566e+04  2e+04  9e-03  1e-14\n",
      " 3: -3.2591e+02 -6.3713e+03  6e+03  3e-03  4e-15\n",
      " 4: -9.9809e+02 -2.7389e+03  2e+03  2e-14  3e-15\n",
      " 5: -1.1512e+03 -1.5394e+03  4e+02  3e-14  2e-15\n",
      " 6: -1.1882e+03 -1.2938e+03  1e+02  7e-15  1e-15\n",
      " 7: -1.1987e+03 -1.2381e+03  4e+01  6e-14  7e-16\n",
      " 8: -1.2028e+03 -1.2182e+03  2e+01  2e-14  7e-16\n",
      " 9: -1.2049e+03 -1.2085e+03  4e+00  1e-13  7e-16\n",
      "10: -1.2055e+03 -1.2060e+03  5e-01  1e-13  7e-16\n",
      "11: -1.2056e+03 -1.2056e+03  2e-02  7e-15  7e-16\n",
      "12: -1.2056e+03 -1.2056e+03  3e-04  4e-14  7e-16\n",
      "Optimal solution found.\n",
      "  The QP solver found Lagrange multipliers of shape (10000,) !\n",
      "  => 5383 support vectors out of 10000 points.\n",
      "  No weight vector, non-linear kernel, will use the Lagrange multipliers self.a ...\n",
      "  Keeping 5383 support vectors.\n",
      "  - For the class k = 1:\n",
      "    There is 1000 examples in this class (and 9000 outside).\n",
      "  Training BinarySVC... on X of shape (10000, 300) ...\n",
      "  Using the given Gram matrix K.\n",
      "  Using the QP solver from cvxopt (cvxopt.qp) ...\n",
      "  More information on http://cvxopt.org/userguide/coneprog.html#quadratic-programming if needed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.8422e+03 -2.1223e+05  4e+05  4e-01  9e-15\n",
      " 1:  5.7817e+03 -5.5759e+04  8e+04  5e-02  4e-15\n",
      " 2:  1.7518e+03 -1.3908e+04  2e+04  9e-03  1e-14\n",
      " 3: -1.7536e+02 -5.6823e+03  6e+03  2e-03  4e-15\n",
      " 4: -8.6571e+02 -1.7199e+03  9e+02  4e-14  3e-15\n",
      " 5: -9.6232e+02 -1.2140e+03  3e+02  5e-14  2e-15\n",
      " 6: -9.9377e+02 -1.0708e+03  8e+01  8e-14  1e-15\n",
      " 7: -1.0049e+03 -1.0251e+03  2e+01  7e-15  1e-15\n",
      " 8: -1.0084e+03 -1.0123e+03  4e+00  3e-14  1e-15\n",
      " 9: -1.0093e+03 -1.0096e+03  3e-01  1e-14  1e-15\n",
      "10: -1.0093e+03 -1.0094e+03  1e-02  5e-14  1e-15\n",
      "11: -1.0094e+03 -1.0094e+03  4e-04  1e-14  1e-15\n",
      "Optimal solution found.\n",
      "  The QP solver found Lagrange multipliers of shape (10000,) !\n",
      "  => 5051 support vectors out of 10000 points.\n",
      "  No weight vector, non-linear kernel, will use the Lagrange multipliers self.a ...\n",
      "  Keeping 5051 support vectors.\n",
      "  - For the class k = 2:\n",
      "    There is 1000 examples in this class (and 9000 outside).\n",
      "  Training BinarySVC... on X of shape (10000, 300) ...\n",
      "  Using the given Gram matrix K.\n",
      "  Using the QP solver from cvxopt (cvxopt.qp) ...\n",
      "  More information on http://cvxopt.org/userguide/coneprog.html#quadratic-programming if needed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.8167e+03 -2.0894e+05  4e+05  3e-01  9e-15\n",
      " 1:  5.0288e+03 -3.8965e+04  5e+04  2e-02  4e-15\n",
      " 2:  5.3762e+02 -1.2246e+04  1e+04  3e-03  5e-15\n",
      " 3: -1.1869e+03 -4.7158e+03  4e+03  7e-15  3e-15\n",
      " 4: -1.4768e+03 -2.0948e+03  6e+02  2e-14  2e-15\n",
      " 5: -1.5231e+03 -1.6926e+03  2e+02  2e-14  1e-15\n",
      " 6: -1.5384e+03 -1.5723e+03  3e+01  6e-14  1e-15\n",
      " 7: -1.5424e+03 -1.5498e+03  7e+00  1e-14  1e-15\n",
      " 8: -1.5435e+03 -1.5445e+03  1e+00  1e-14  1e-15\n",
      " 9: -1.5437e+03 -1.5437e+03  6e-02  5e-14  1e-15\n",
      "10: -1.5437e+03 -1.5437e+03  2e-03  4e-15  1e-15\n",
      "11: -1.5437e+03 -1.5437e+03  4e-05  5e-14  1e-15\n",
      "Optimal solution found.\n",
      "  The QP solver found Lagrange multipliers of shape (10000,) !\n",
      "  => 6910 support vectors out of 10000 points.\n",
      "  No weight vector, non-linear kernel, will use the Lagrange multipliers self.a ...\n",
      "  Keeping 6910 support vectors.\n",
      "  - For the class k = 3:\n",
      "    There is 1000 examples in this class (and 9000 outside).\n",
      "  Training BinarySVC... on X of shape (10000, 300) ...\n",
      "  Using the given Gram matrix K.\n",
      "  Using the QP solver from cvxopt (cvxopt.qp) ...\n",
      "  More information on http://cvxopt.org/userguide/coneprog.html#quadratic-programming if needed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.3896e+03 -2.2066e+05  4e+05  3e-01  9e-15\n",
      " 1:  4.8442e+03 -3.9973e+04  5e+04  1e-02  4e-15\n",
      " 2:  4.9680e+02 -1.3230e+04  1e+04  3e-03  6e-15\n",
      " 3: -1.0375e+03 -6.7229e+03  6e+03  8e-04  3e-15\n",
      " 4: -1.4789e+03 -3.8218e+03  2e+03  7e-14  2e-15\n",
      " 5: -1.6144e+03 -2.0832e+03  5e+02  2e-14  2e-15\n",
      " 6: -1.6416e+03 -1.7567e+03  1e+02  5e-14  1e-15\n",
      " 7: -1.6498e+03 -1.6767e+03  3e+01  1e-13  1e-15\n",
      " 8: -1.6524e+03 -1.6568e+03  4e+00  4e-14  1e-15\n",
      " 9: -1.6529e+03 -1.6534e+03  5e-01  6e-14  1e-15\n",
      "10: -1.6530e+03 -1.6530e+03  2e-02  4e-14  1e-15\n",
      "11: -1.6530e+03 -1.6530e+03  7e-04  1e-13  1e-15\n",
      "Optimal solution found.\n",
      "  The QP solver found Lagrange multipliers of shape (10000,) !\n",
      "  => 7503 support vectors out of 10000 points.\n",
      "  No weight vector, non-linear kernel, will use the Lagrange multipliers self.a ...\n",
      "  Keeping 7503 support vectors.\n",
      "  - For the class k = 4:\n",
      "    There is 1000 examples in this class (and 9000 outside).\n",
      "  Training BinarySVC... on X of shape (10000, 300) ...\n",
      "  Using the given Gram matrix K.\n",
      "  Using the QP solver from cvxopt (cvxopt.qp) ...\n",
      "  More information on http://cvxopt.org/userguide/coneprog.html#quadratic-programming if needed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.1329e+03 -2.2668e+05  5e+05  4e-01  1e-14\n",
      " 1:  4.6433e+03 -4.3926e+04  6e+04  2e-02  5e-15\n",
      " 2:  7.8133e+02 -1.3493e+04  2e+04  5e-03  7e-15\n",
      " 3: -1.1445e+03 -4.1268e+03  3e+03  1e-14  5e-15\n",
      " 4: -1.4457e+03 -1.9299e+03  5e+02  9e-14  3e-15\n",
      " 5: -1.4979e+03 -1.6176e+03  1e+02  3e-14  2e-15\n",
      " 6: -1.5136e+03 -1.5411e+03  3e+01  8e-14  2e-15\n",
      " 7: -1.5181e+03 -1.5236e+03  5e+00  6e-14  2e-15\n",
      " 8: -1.5192e+03 -1.5201e+03  9e-01  2e-14  2e-15\n",
      " 9: -1.5194e+03 -1.5195e+03  7e-02  4e-14  2e-15\n",
      "10: -1.5194e+03 -1.5194e+03  3e-03  1e-13  2e-15\n",
      "11: -1.5194e+03 -1.5194e+03  7e-05  9e-14  2e-15\n",
      "Optimal solution found.\n",
      "  The QP solver found Lagrange multipliers of shape (10000,) !\n",
      "  => 5957 support vectors out of 10000 points.\n",
      "  No weight vector, non-linear kernel, will use the Lagrange multipliers self.a ...\n",
      "  Keeping 5957 support vectors.\n",
      "  - For the class k = 5:\n",
      "    There is 1000 examples in this class (and 9000 outside).\n",
      "  Training BinarySVC... on X of shape (10000, 300) ...\n",
      "  Using the given Gram matrix K.\n",
      "  Using the QP solver from cvxopt (cvxopt.qp) ...\n",
      "  More information on http://cvxopt.org/userguide/coneprog.html#quadratic-programming if needed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.4721e+03 -2.0385e+05  4e+05  3e-01  9e-15\n",
      " 1:  4.5081e+03 -3.8964e+04  5e+04  2e-02  4e-15\n",
      " 2:  6.5674e+02 -1.2657e+04  1e+04  5e-03  6e-15\n",
      " 3: -6.4297e+02 -7.1967e+03  7e+03  2e-03  3e-15\n",
      " 4: -1.2010e+03 -4.1224e+03  3e+03  1e-13  2e-15\n",
      " 5: -1.4112e+03 -1.9244e+03  5e+02  2e-14  2e-15\n",
      " 6: -1.4531e+03 -1.5784e+03  1e+02  8e-14  1e-15\n",
      " 7: -1.4640e+03 -1.4987e+03  3e+01  2e-14  1e-15\n",
      " 8: -1.4676e+03 -1.4760e+03  8e+00  4e-14  1e-15\n",
      " 9: -1.4687e+03 -1.4704e+03  2e+00  3e-14  1e-15\n",
      "10: -1.4689e+03 -1.4691e+03  1e-01  1e-13  1e-15\n",
      "11: -1.4690e+03 -1.4690e+03  5e-03  1e-13  1e-15\n",
      "12: -1.4690e+03 -1.4690e+03  1e-04  7e-14  1e-15\n",
      "Optimal solution found.\n",
      "  The QP solver found Lagrange multipliers of shape (10000,) !\n",
      "  => 6439 support vectors out of 10000 points.\n",
      "  No weight vector, non-linear kernel, will use the Lagrange multipliers self.a ...\n",
      "  Keeping 6439 support vectors.\n",
      "  - For the class k = 6:\n",
      "    There is 1000 examples in this class (and 9000 outside).\n",
      "  Training BinarySVC... on X of shape (10000, 300) ...\n",
      "  Using the given Gram matrix K.\n",
      "  Using the QP solver from cvxopt (cvxopt.qp) ...\n",
      "  More information on http://cvxopt.org/userguide/coneprog.html#quadratic-programming if needed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.6141e+03 -1.9085e+05  4e+05  3e-01  1e-14\n",
      " 1:  4.3464e+03 -2.9724e+04  4e+04  1e-02  4e-15\n",
      " 2:  7.6780e+02 -1.0656e+04  1e+04  4e-03  6e-15\n",
      " 3: -9.0237e+02 -3.4647e+03  3e+03  5e-14  5e-15\n",
      " 4: -1.1637e+03 -1.6524e+03  5e+02  2e-14  2e-15\n",
      " 5: -1.2161e+03 -1.3416e+03  1e+02  4e-15  2e-15\n",
      " 6: -1.2323e+03 -1.2666e+03  3e+01  5e-14  1e-15\n",
      " 7: -1.2378e+03 -1.2453e+03  7e+00  4e-14  1e-15\n",
      " 8: -1.2392e+03 -1.2411e+03  2e+00  7e-15  1e-15\n",
      " 9: -1.2396e+03 -1.2398e+03  2e-01  3e-14  1e-15\n",
      "10: -1.2396e+03 -1.2396e+03  9e-03  9e-15  1e-15\n",
      "11: -1.2396e+03 -1.2396e+03  3e-04  5e-14  1e-15\n",
      "Optimal solution found.\n",
      "  The QP solver found Lagrange multipliers of shape (10000,) !\n",
      "  => 5386 support vectors out of 10000 points.\n",
      "  No weight vector, non-linear kernel, will use the Lagrange multipliers self.a ...\n",
      "  Keeping 5386 support vectors.\n",
      "  - For the class k = 7:\n",
      "    There is 1000 examples in this class (and 9000 outside).\n",
      "  Training BinarySVC... on X of shape (10000, 300) ...\n",
      "  Using the given Gram matrix K.\n",
      "  Using the QP solver from cvxopt (cvxopt.qp) ...\n",
      "  More information on http://cvxopt.org/userguide/coneprog.html#quadratic-programming if needed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.3945e+03 -2.1947e+05  5e+05  4e-01  9e-15\n",
      " 1:  5.6649e+03 -4.5533e+04  6e+04  3e-02  4e-15\n",
      " 2:  1.2210e+03 -1.2793e+04  1e+04  5e-03  6e-15\n",
      " 3: -4.9434e+02 -5.8169e+03  5e+03  1e-03  4e-15\n",
      " 4: -1.1033e+03 -1.9907e+03  9e+02  2e-14  3e-15\n",
      " 5: -1.1874e+03 -1.4176e+03  2e+02  7e-15  2e-15\n",
      " 6: -1.2128e+03 -1.2725e+03  6e+01  4e-14  1e-15\n",
      " 7: -1.2208e+03 -1.2355e+03  1e+01  3e-14  1e-15\n",
      " 8: -1.2232e+03 -1.2258e+03  3e+00  2e-14  1e-15\n",
      " 9: -1.2237e+03 -1.2240e+03  3e-01  1e-13  1e-15\n",
      "10: -1.2237e+03 -1.2238e+03  2e-02  8e-14  1e-15\n",
      "11: -1.2237e+03 -1.2237e+03  8e-04  9e-14  1e-15\n",
      "Optimal solution found.\n",
      "  The QP solver found Lagrange multipliers of shape (10000,) !\n",
      "  => 5934 support vectors out of 10000 points.\n",
      "  No weight vector, non-linear kernel, will use the Lagrange multipliers self.a ...\n",
      "  Keeping 5934 support vectors.\n",
      "  - For the class k = 8:\n",
      "    There is 1000 examples in this class (and 9000 outside).\n",
      "  Training BinarySVC... on X of shape (10000, 300) ...\n",
      "  Using the given Gram matrix K.\n",
      "  Using the QP solver from cvxopt (cvxopt.qp) ...\n",
      "  More information on http://cvxopt.org/userguide/coneprog.html#quadratic-programming if needed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.2496e+03 -2.5262e+05  6e+05  5e-01  9e-15\n",
      " 1:  5.5476e+03 -6.6217e+04  1e+05  6e-02  3e-15\n",
      " 2:  1.9703e+03 -1.5408e+04  2e+04  1e-02  7e-15\n",
      " 3: -4.1496e+01 -6.8811e+03  7e+03  3e-03  4e-15\n",
      " 4: -8.4274e+02 -2.9889e+03  2e+03  2e-14  3e-15\n",
      " 5: -1.0330e+03 -1.4977e+03  5e+02  9e-14  2e-15\n",
      " 6: -1.0731e+03 -1.2373e+03  2e+02  7e-14  1e-15\n",
      " 7: -1.0882e+03 -1.1430e+03  5e+01  1e-14  8e-16\n",
      " 8: -1.0943e+03 -1.1092e+03  1e+01  6e-14  7e-16\n",
      " 9: -1.0963e+03 -1.0997e+03  3e+00  6e-14  7e-16\n",
      "10: -1.0969e+03 -1.0973e+03  4e-01  2e-16  7e-16\n",
      "11: -1.0970e+03 -1.0970e+03  1e-02  7e-14  7e-16\n",
      "12: -1.0970e+03 -1.0970e+03  3e-04  1e-14  7e-16\n",
      "Optimal solution found.\n",
      "  The QP solver found Lagrange multipliers of shape (10000,) !\n",
      "  => 5303 support vectors out of 10000 points.\n",
      "  No weight vector, non-linear kernel, will use the Lagrange multipliers self.a ...\n",
      "  Keeping 5303 support vectors.\n",
      "  - For the class k = 9:\n",
      "    There is 1000 examples in this class (and 9000 outside).\n",
      "  Training BinarySVC... on X of shape (10000, 300) ...\n",
      "  Using the given Gram matrix K.\n",
      "  Using the QP solver from cvxopt (cvxopt.qp) ...\n",
      "  More information on http://cvxopt.org/userguide/coneprog.html#quadratic-programming if needed\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.5535e+03 -2.3965e+05  5e+05  4e-01  9e-15\n",
      " 1:  6.1726e+03 -4.9421e+04  7e+04  3e-02  4e-15\n",
      " 2:  1.5300e+03 -1.4098e+04  2e+04  6e-03  6e-15\n",
      " 3: -2.4891e+02 -6.7375e+03  7e+03  2e-03  4e-15\n",
      " 4: -9.5589e+02 -2.4091e+03  1e+03  1e-13  3e-15\n",
      " 5: -1.0797e+03 -1.4130e+03  3e+02  7e-15  1e-15\n",
      " 6: -1.1128e+03 -1.2069e+03  9e+01  2e-14  1e-15\n",
      " 7: -1.1249e+03 -1.1453e+03  2e+01  3e-14  1e-15\n",
      " 8: -1.1282e+03 -1.1316e+03  3e+00  9e-16  1e-15\n",
      " 9: -1.1289e+03 -1.1293e+03  4e-01  6e-14  1e-15\n",
      "10: -1.1290e+03 -1.1290e+03  1e-02  2e-14  1e-15\n",
      "11: -1.1290e+03 -1.1290e+03  3e-04  9e-15  1e-15\n",
      "Optimal solution found.\n",
      "  The QP solver found Lagrange multipliers of shape (10000,) !\n",
      "  => 5754 support vectors out of 10000 points.\n",
      "  No weight vector, non-linear kernel, will use the Lagrange multipliers self.a ...\n",
      "  Keeping 5754 support vectors.\n",
      "  Projecting on a 10-class SVC for data X of shape (10000, 300) ...\n",
      "  Not using any parallelism for projectOneBinarySVC(k) for k = 0 .. 9 ...\n",
      "    Projecting on the 0-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (10000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 1-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (10000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 2-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (10000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 3-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (10000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 4-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (10000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 5-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (10000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 6-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (10000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 7-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (10000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 8-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (10000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 9-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (10000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "  Predicting on a 10-class SVC for data X of shape (10000, 300) ...\n",
      "  Stats about the predictions:\n",
      " [(0, 1000), (1, 1000), (2, 1000), (3, 1000), (4, 1000), (5, 1000), (6, 1000), (7, 1000), (8, 1000), (9, 1000)]\n",
      "[SUCCESS UNLOCKED] clf.score(X, y): the computed score is exactly 1 ! Yeepee ! Exact prediction ! YOUUUU\n",
      "Checking the score on the train data : 100.00% ...\n",
      "Prediction on test data ...\n",
      "  Projecting on a 10-class SVC for data X of shape (2000, 300) ...\n",
      "  Not using any parallelism for projectOneBinarySVC(k) for k = 0 .. 9 ...\n",
      "    Projecting on the 0-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (2000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 1-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (2000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 2-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (2000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 3-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (2000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 4-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (2000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 5-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (2000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 6-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (2000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 7-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (2000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 8-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (2000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "    Projecting on the 9-th BinarySVC ...\n",
      "  Projecting on a BinarySVC for data X of shape (2000, 300) ...\n",
      "    Non-linear kernel, using self.a, self.sv and self.sv_y ...\n",
      "  Predicting on a 10-class SVC for data X of shape (2000, 300) ...\n",
      "  Stats about the predictions:\n",
      " [(0, 239), (1, 223), (2, 167), (3, 137), (4, 200), (5, 189), (6, 223), (7, 212), (8, 198), (9, 212)]\n"
     ]
    }
   ],
   "source": [
    "# Train model on known data\n",
    "\n",
    "svm_parameters = {\n",
    "    'kernel': 'ch2',  # Example kernel type\n",
    "    'C': 7.5,          # Example regularization parameter\n",
    "    # Add more parameters as needed\n",
    "}\n",
    "\n",
    "svm_model = mySVC(**svm_parameters)\n",
    "print(\"Training SVM on all training data ...\")\n",
    "target = np.array(target) \n",
    "svm_model.fit(train, target)\n",
    "\n",
    "# Verify results on known data (gives you a hint on whether you are overfitting)\n",
    "\n",
    "CHECK_SCORE_TRAIN_DATA = True\n",
    "if CHECK_SCORE_TRAIN_DATA:\n",
    "    train_score = svm_model.score(train, target)\n",
    "    print(\"Checking the score on the train data : {:.2%} ...\".format(train_score))\n",
    "\n",
    "# Prediction on non labelled data\n",
    "print(\"Prediction on test data ...\")\n",
    "prediction = svm_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the predictions to the CSV file 'Submission_SVM_Kernelch2_C=7.5_flipimage_NS.csv' ...\n"
     ]
    }
   ],
   "source": [
    "# Saving the predictions\n",
    "\n",
    "outname = 'Submission_SVM_Kernel%s_C=%s_flipimage_NS.csv' % (svm_parameters['kernel'], svm_parameters['C'])\n",
    "print(\"Saving the predictions to the CSV file '%s' ...\" % outname)\n",
    "\n",
    "# Saving to 'outname', and to 'Yte.csv' \n",
    "for on in [outname, 'Yte.csv']:\n",
    "    np.savetxt(on,\n",
    "               np.c_[range(1, len(test) + 1), prediction],\n",
    "               delimiter=',',\n",
    "               comments='',\n",
    "               header='Id,Prediction',\n",
    "               fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
